# -*- coding: utf-8 -*-
"""redesConv2d.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QY9Zb0h9dxlSuELEL7skfYs3Jg9eMKXT
"""

import argparse
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow.keras as keras
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras import models, layers, optimizers, losses, metrics
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape
from tensorflow.keras.optimizers import RMSprop

# constants and hyperparameters
MAX_WORD_INDEX = 10000

BATCH_SIZE = 128
NUM_EPOCHS = 200
LR = 0.001
BETA1 = 0.9
BETA2 = 0.999
EPSILON = 1.0e-8
DECAY = 0.0
VAL_PERC = 0.4
EMBEDDING_DIM = 32
NUM_LSTM_UNITS = 32
DROPOUT_RATE = 0.5

# load database using Keras
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = MAX_WORD_INDEX)
max_features= imdb.load_data(num_words = MAX_WORD_INDEX)

#  print some information on the data
max_seq_len_train = max([len(sequence) for sequence in train_data])
max_seq_len_test = max([len(sequence) for sequence in test_data])
min_seq_len_train = min([len(sequence) for sequence in train_data])
min_seq_len_test = min([len(sequence) for sequence in test_data])
print(f'Maximum train sequence length: {max_seq_len_train}')
print(f'Maximum test sequence length: {max_seq_len_test}')
print(f'Minimum train sequence length: {min_seq_len_train}')
print(f'Minimum test sequence length: {min_seq_len_test}')

# pad sequences
X_train = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=500)
X_test = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=500)



print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")

# transform labels into arrays
y_train = np.asarray(train_labels).astype("float32")
y_test = np.asarray(test_labels).astype("float32")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

# split training data into training and validation
nsamples = X_train.shape[0]
np.random.seed(0)
idx = np.arange(nsamples)
np.random.shuffle(idx)

nval = int(0.1 * nsamples)
X_val = X_train[idx[:nval]]
y_val = y_train[idx[:nval]]
X_train_new = X_train[idx[nval:]]
y_train_new = y_train[idx[nval:]]
print(X_train_new.shape)
print(y_train_new.shape)
print(X_val.shape)
print(y_val.shape)

model = Sequential()
model.add(Embedding(MAX_WORD_INDEX, EMBEDDING_DIM, input_length=500))
model.add(Reshape((500, EMBEDDING_DIM, 1)))
model.add(Conv2D(32, kernel_size=(7,7), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPooling2D((5, 5)))
model.add(Dropout(DROPOUT_RATE))
model.add(Conv2D(64, kernel_size=(7,7), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPooling2D((3, 3)))
model.add(Dropout(DROPOUT_RATE))
model.add(Conv2D(128, kernel_size=(7,7), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(DROPOUT_RATE))
model.add(Dense(64, activation='relu'))
model.add(Dropout(DROPOUT_RATE))
model.add(Dense(1, activation='sigmoid'))
print(model.summary())

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])

# fit model to data
history = model.fit(X_train_new, y_train_new,
                    epochs=NUM_EPOCHS,
                    batch_size=BATCH_SIZE,
                    validation_data=(X_val, y_val),
                    verbose=1)

# learning curves
history_dict = history.history
history_dict.keys()

# losses
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']

# accuracies
acc_values = history_dict['binary_accuracy']
val_acc_values = history_dict['val_binary_accuracy']

epochs = range(NUM_EPOCHS)

fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,8))

ax1.plot(epochs, loss_values, 'bo', label="Training Loss")
ax1.plot(epochs, val_loss_values, 'b', label="Validation Loss")
ax1.set_title('Training and Validation Loss')
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss Value')
ax1.legend()

ax2.plot(epochs, acc_values, 'ro', label="Training Accuracy")
ax2.plot(epochs, val_acc_values, 'r', label="Validation Accuracy")
ax2.set_title('Training and Validation Accuracy')
ax2.set_xlabel('Epochs')
ax2.set_ylabel('Accuracy')
ax2.legend()

plt.show()